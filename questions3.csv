題號,題目,選項1,選項2,選項3,選項4,答案,答案精簡說明,
1,在強化學習領域中，主要的策略目標是什麼？,提高數據的準確性,最大化累計獎勵,最小化模型複雜度,減少訓練時間,B,最大化累計獎勵是強化學習的根本目標。,
2,隨機森林演算法屬於哪種類型的演算法？,線性模型,集成學習,非監督式學習,強化學習,B,隨機森林是將多個決策樹組合的集成學習方法。,
3,資料轉換（Data Transformation）中，「特徵標準化（Standardization）」的目的是什麼？,將數據轉換為均值為0、標準差為1的分布,增強圖像邊緣,將數據壓縮到固定範圍內,增加資料筆數,A,標準化將數據轉換為平均值為0、標準差為1的分佈。,
4,鑑別式AI（Discriminative AI）的原理是？,根據已有的輸入序列預測下一個最有可能出現的詞元,學習不同類別資料之間的「決策邊界」,生成全新的數據樣本,僅限於處理圖像和語音數據,B,鑑別式AI旨在學習區分不同類別的邊界。,
5,在編碼器-解碼器架構中，哪種輸出詞元選擇方法是最簡單的，每次都選擇機率最高的詞元？,集束搜索 (Beam Search),貪婪搜索 (Greedy Search),採樣 (Sampling),序列到序列學習,B,貪婪搜索在每一步都選擇當前機率最高的詞元。,
6,「MSE」（Mean Squared Error）主要用於評估哪種類型的機器學習問題？,分類問題,聚類問題,迴歸問題,維度縮減問題,C,MSE用於衡量迴歸模型預測值與真實值之間的平均平方差。,
7,在歐盟AI法案中，被歸類為「不可接受的風險」的AI系統，下列哪項是其典型例子？,垃圾郵件過濾器,用於醫院的輔助診斷AI,公共場所用於執法目的的實時遠端生物識別識別系統,個人化商品推薦系統,C,實時遠端生物識別識別系統（公共場所執法目的）被列為不可接受風險。,
8,Google Cloud的AI應用開發工具平台是什麼？,TensorFlow,Vertex AI,Keras,PyTorch,B,Vertex AI是Google Cloud整合式機器學習開發平台。,
9,L1正則化（Lasso Regression）在模型訓練中主要會產生什麼效果？,將所有權重壓縮到接近零,將一些權重完全壓縮為零，實現特徵選擇,增加模型的複雜度,加速模型的訓練速度,B,L1正則化具有稀疏性，會將不重要特徵的權重設為零。,
10,L2正則化（Ridge Regression）在處理特徵共線性問題時有何優勢？,完全移除共線特徵,將相關特徵的權重等比例壓縮，使其更穩定,僅對共線特徵進行懲罰,增加特徵的數量,B,L2正則化能有效處理共線性，將相關特徵的權重等比例縮小。,
11,大數據的5V特性中，描述數據來源和格式多樣性的是哪個V？,Volume (資料量),Velocity (處理速度),Variety (資料多樣性),Veracity (資料真實性),C,Variety指數據的類型和格式多樣化。,
12,大數據的5V特性中，描述數據規模非常巨大的是哪個V？,Volume (資料量),Velocity (處理速度),Variety (資料多樣性),Value (資料價值),A,Volume指的是數據的體積或規模。,
13,大數據的5V特性中，描述數據產生和處理速度非常快的是哪個V？,Volume (資料量),Velocity (處理速度),Variety (資料多樣性),Veracity (資料真實性),B,Velocity指的是數據處理的實時性或近實時性。,
14,大數據的5V特性中，描述數據的質量、準確性和可信度的是哪個V？,Volume (資料量),Velocity (處理速度),Variety (資料多樣性),Veracity (資料真實性),D,Veracity關注數據的可靠性。,
15,大數據的5V特性中，描述從數據中提取有意義、有商業價值的資訊的能力是哪個V？,Variety (資料多樣性),Velocity (處理速度),Veracity (資料真實性),Value (資料價值),D,Value指從數據中挖掘潛在的商業價值。,
16,在OSEMN數據處理流程中，哪一步驟主要處理缺失值、異常值和重複數據？,Obtain (獲取數據),Scrub (清洗數據),Explore (探索數據),Model (建立模型),B,Scrubing專注於數據清理和預處理。,
17,在OSEMN數據處理流程中，哪一步驟主要進行數據視覺化和統計摘要？,Obtain (獲取數據),Scrub (清洗數據),Explore (探索數據),Model (建立模型),C,Explore階段進行探索性數據分析（EDA）。,
18,在OSEMN數據處理流程中，哪一步驟涉及選擇演算法、訓練模型和評估模型性能？,Scrub (清洗數據),Explore (探索數據),Model (建立模型),Narrate (解釋與展示),C,Model階段包含模型的選擇、訓練和初步評估。,
19,在OSEMN數據處理流程中，N（Narrate）的主要目標是什麼？,將模型應用於新數據,將分析結果和模型見解清晰地傳達給決策者,清洗數據中的錯誤,探索數據的內在模式,B,Narrate旨在有效溝通分析結果。,
20,特徵標準化後，數據的平均值和標準差分別為多少？,平均值為1，標準差為0,平均值為0，標準差為1,平均值為任意值，標準差為1,平均值為0，標準差為任意值,B,標準化將數據中心化並單位化。,
21,鑑別式AI模型直接學習什麼？,數據的生成分佈,條件機率P(Y|X)或從X到Y的映射,聯合機率P(X Y),數據的潛在表示,B,鑑別式模型直接學習如何區分類別。,
22,生成式AI模型通常學習什麼？,決策邊界,條件機率P(Y|X),數據的生成分佈P(X)或聯合機率P(XY),特徵的重要性,C,生成式模型旨在理解數據的生成機制。,
23,在深度學習中，Perplexity（困惑度）通常用於評估哪種模型？,圖像分類模型,語言模型,推薦系統,物件檢測模型,B,困惑度衡量語言模型預測文本序列的能力。,
24,「維度詛咒」在高維度數據中主要體現在哪一方面？,數據量減少,數據在空間中變得極度稀疏，距離難以區分,計算複雜度降低,模型自動進行特徵選擇,B,維度詛咒指出高維空間中數據的稀疏性。,
25,下列哪項是大規模生物識別系統在歐盟AI法案中最嚴格的風險分類的例子？,在銀行用於身分驗證的指紋識別系統,在公共場所用於執法目的的實時遠端人臉識別系統,用於公司門禁的員工卡掃描系統,個人手機上的臉部解鎖功能,B,公共場所實時遠端生物識別識別是歐盟AI法案中的禁止類別。,
26,ETL流程中，哪一步驟通常最耗時且最複雜？,Extract (擷取),Transform (轉換),Load (載入),All steps equally complex,B,Transform階段涉及數據清理、轉換和整合，通常最複雜耗時。,
27,ETL流程中，用於從不同數據庫、文件和API中獲取數據的步驟是？,Transform (轉換),Load (載入),Extract (擷取),Monitor (監控),C,Extract是從源頭收集數據。,
28,ETL流程中，將處理後的數據寫入數據倉庫的步驟是？,Extract (擷取),Transform (轉換),Load (載入),Validate (驗證),C,Load是將數據最終存儲到目標系統。,
29,VAE（變分自動編碼器）屬於哪種類型的AI模型？,辨別式模型,生成式模型,監督式學習模型,強化學習模型,B,VAE是一種生成式模型，用於學習數據分佈和生成新樣本。,
30,VAE的核心目標之一是學習數據的什麼？,決策邊界,潛在表示（Latent Representation）,最優分類閾值,迴歸函數,B,VAE旨在學習數據的低維潛在表示。,
31,VAE的損失函數通常包含哪兩部分？,準確度和召回率,重建損失和KL散度損失,MSE和交叉熵,精確度和F1分數,B,重建損失衡量重建質量，KL散度損失約束潛在空間分佈。,
32,Position Encoding（位置編碼）主要解決了Transformer架構的什麼問題？,處理圖像數據的能力,無法區分序列中詞元的位置信息,訓練時間過長,對異常值敏感,B,Transformer是並行處理，需要位置編碼來理解詞元順序。,
33,在Transformer中，正弦位置編碼（Sinusoidal Position Encoding）的優點之一是？,需大量數據訓練,無需學習，可處理任意長度序列,易於處理非線性關係,自動進行特徵選擇,B,正弦位置編碼是固定計算的，不需要額外訓練。,
34,在Transformer中，可學習的位置編碼（Learned Position Encoding）的缺點之一是？,無法處理短序列,無法外推到比訓練時更長的序列,計算效率極低,需要手動調整參數,B,可學習位置編碼對未見過的長度序列無法直接應用。,
35,與L1正則化相比，L2正則化在處理哪個問題時通常表現更好？,特徵選擇,數據稀疏性,特徵間的高度共線性,模型解釋性,C,L2正則化通過均勻縮小權重來穩定處理共線性。,
36,在評估圖像生成模型時，FID分數越低代表什麼？,生成圖像的多樣性越差,生成圖像的真實性越差,生成圖像的質量越好，越接近真實分佈,模型更容易過擬合,C,FID越低表示生成圖像與真實圖像分佈越接近，質量越好。,
37,哪個指標用於評估文本摘要和機器翻譯中生成文本的品質？,FID,BLEU,MSE,Perplexity,B,BLEU和ROUGE是文本生成的常用指標。,
38,維度詛咒主要導致高維度數據的什麼問題？,數據過於密集,數據在空間中變得稀疏，距離難以有意義,數據量不足,模型訓練速度變快,B,稀疏性使得高維空間中的距離度量失效。,
39,歐盟AI法案中，對AI系統的監管嚴格程度取決於什麼？,AI系統的開發成本,AI系統對人類可能造成的風險水平,AI系統的程式碼行數,AI系統的計算資源消耗,B,法案採用風險分級方法。,
40,「高風險」AI系統在歐盟AI法案中需要履行的義務不包括？,建立風險管理系統,提供詳細技術文件和日誌,必須完全禁止使用,確保數據的高質量和無偏見,C,高風險系統需嚴格監管而非禁止。,
41,下列哪種AI系統在歐盟AI法案中屬於「有限風險」，需要透明度義務？,用於關鍵基礎設施的AI,自動駕駛系統的AI,告知用戶正在與AI互動的聊天機器人,軍事武器中的AI,C,聊天機器人需要告知用戶AI互動。,
42,RLHF流程中，人類回饋主要用於訓練什麼？,初始預訓練的LLM,獎勵模型 (Reward Model),環境模擬器,生成器模型,B,人類回饋用於訓練獎勵模型來評估LLM輸出。,
43,數據的四分位距（IQR）是哪個分位數之間的距離？,Q1和Q2,Q1和Q3,Q2和Q3,最小值和最大值,B,IQR是第三四分位數和第一四分位數之間的差值。,
44,與全距（Range）相比，四分位距（IQR）在衡量數據分散程度時有何優勢？,對異常值更敏感,計算更複雜,對異常值不敏感，更穩健,只能用於正態分佈數據,C,IQR不考慮極端值，對異常值魯棒。,
45,使用四分位距（IQR）來判斷異常值時，常用的經驗法則是什麼？,小於Q1或大於Q3的數據點,小於Q1 - 1.5 * IQR或大於Q3 + 1.5 * IQR的數據點,超過平均值三個標準差的數據點,位於中位數之外的數據點,B,這是箱形圖鬍鬚的定義，常用於異常值識別。,
46,在處理高維度數據時，哪種技術可以將數據轉換到一個較低維度的空間，同時保留重要信息？,特徵標準化,數據增強,特徵提取/降維,數據去重,C,降維是處理高維度數據的關鍵方法。,
47,主成分分析（PCA）屬於哪種類型的高維數據處理方法？,特徵選擇,特徵提取/降維,數據增強,模型評估,B,PCA是一種常用的線性降維技術。,
48,下列哪項不屬於機器學習中的「正則化」技術？,L1 正則化,L2 正則化,Dropout,特徵工程,D,特徵工程是數據預處理步驟，不屬於正則化。,
49,在機器學習中，模型在訓練數據上表現非常好，但在未見過的新數據上表現很差的現象稱為？,欠擬合 (Underfitting),過擬合 (Overfitting),泛化能力強 (Strong Generalization),數據噪音 (Data Noise),B,過擬合是模型過度學習訓練數據的特有模式。,
50,為了提升模型的泛化能力，下列哪種方法是有效的？,減少訓練數據量,只使用最簡單的模型,進行數據增強或使用正則化,僅在訓練數據上評估模型性能,C,數據增強和正則化有助於模型泛化。,
51,如果一個模型連在訓練數據上都表現不佳，這最可能表明什麼問題？,過擬合 (Overfitting),欠擬合 (Underfitting),模型過於複雜,數據量過大,B,欠擬合是指模型未能充分學習數據。,
52,Azure OpenAI服務主要提供哪些模型？,TensorFlow和Keras,GPT系列、DALL-E、Embeddings,Apache Spark,傳統資料庫服務,B,Azure OpenAI提供OpenAI旗艦模型。,
53,Azure OpenAI服務與傳統Azure AI服務相比，一個主要的安全優勢是？,數據直接在公共網絡處理,數據可以部署在企業的私有網絡中,不支持任何身分驗證,無法與其他Azure服務整合,B,私有網絡部署是其重要的企業級安全特性。,
54,Azure OpenAI服務允許企業使用自己的數據對模型進行什麼操作以適應特定場景？,刪除模型,微調 (Fine-tuning),改變模型架構,僅限於預設模型,B,微調是定製模型以適應特定數據和任務的方法。,
55,ETL流程中「Transform」階段的一個常見操作是？,從CSV文件讀取數據,將數據寫入數據倉庫表,處理缺失值和數據類型轉換,監控數據倉庫性能,C,處理缺失值和類型轉換都是Transform的常見任務。,
56,如果一個迴歸模型的MSE值非常大，這通常意味著什麼？,模型有很好的泛化能力,模型的預測值與真實值之間存在較大差異,模型已經嚴重過擬合,模型訓練速度很快,B,大的MSE表示預測誤差大。,
57,在比較L1和L2正則化時，哪種正則化方法會導致模型權重更稀疏？,L1 正則化,L2 正則化,兩種都一樣,取決於學習率,A,L1正則化會促使部分權重為零。,
58,大數據的5V特性中，「Volume」指的是數據的什麼方面？,數據的格式種類,數據的處理速度,數據的巨大體積,數據的準確性,C,Volume特指數據量的龐大。,
59,在分類問題中，如果一個邏輯迴歸模型的Sigmoid函數輸出值為0.8，且閾值設為0.5，那麼模型會預測為哪個類別？,類別0,類別1,無法判斷,需要更多資訊,B,0.8大於0.5，所以預測為類別1。,
60,下列哪項不是提升AI模型泛化能力的常用方法？,增加訓練數據量,減少正則化,使用交叉驗證,進行數據增強,B,減少正則化可能會增加過擬合風險。,
61,在深度學習中，為了給Transformer模型提供詞元之間的序列信息，通常使用什麼技術？,卷積層,池化層,位置編碼,批次歸一化,C,位置編碼是Transformer理解順序的關鍵。,
62,歐盟AI法案主要關注AI系統的什麼？,AI的計算效率,AI對人類權利和安全的風險,AI模型的訓練速度,AI應用程式的用戶界面設計,B,法案的核心是基於風險的監管。,
63,下列哪種數據不屬於「高維度數據」的典型例子？,圖像數據（數千像素）,文本數據（數萬詞彙）,基因組學數據,一個只包含身高體重的數據集,D,身高體重僅為二維數據，非高維。,
64,當我們說一個AI模型「過擬合」時，它在訓練數據和測試數據上的表現如何？,訓練數據好，測試數據好,訓練數據差，測試數據差,訓練數據好，測試數據差,訓練數據差，測試數據好,C,過擬合是模型在訓練集上表現過度優異，但在未見數據上表現不佳。,
65,機器學習中，用來量化模型預測連續數值與真實值之間平均差異的指標是？,準確度,精確度,均方誤差 (MSE),召回率,C,MSE專門用於迴歸問題的誤差衡量。,
66,Lasso正則化之所以能進行特徵選擇，是因為其懲罰項會促使部分權重變為什麼？,趨近於無限大,完全為零,變成負數,保持不變,B,L1正則化可以將不重要的特徵權重歸零。,
67,在一個數據集上進行分位數計算，如果Q1為25，Q3為75，那麼IQR是多少？,25,50,75,100,B,IQR = Q3 - Q1 = 75 - 25 = 50。,
68,四分位距（IQR）的主要優勢之一是它對什麼不那麼敏感？,中位數,均值,異常值,數據量,C,IQR不考慮數據的極端值，因此受異常值影響小。,
69,VAE訓練中的「重參數化技巧 (Reparameterization Trick)」主要用於解決什麼問題？,防止模型過擬合,讓梯度可以從重建損失反向傳播回潛在分佈的參數,加速模型訓練速度,處理缺失數據,B,重參數化技巧允許梯度通過採樣操作傳播。,
70,VAE的解碼器接收什麼作為輸入來生成新的數據？,原始輸入數據,從編碼器輸出的潛在分佈中採樣得到的潛在向量,固定的隨機數,其他模型的輸出,B,解碼器從潛在空間採樣點來生成。,
71,如果你想在Google Cloud上使用OpenAI的GPT-4模型，你會選擇哪個服務？,Google Kubernetes Engine,Google Cloud Storage,Vertex AI,Azure OpenAI 服務,C,Vertex AI是Google Cloud的整合ML平台，支持多種模型包括像GPT-4這種通用大型模型（通過API或直接使用）。[Note: This question might be tricky if the user literally thought about *Azure* OpenAI Service. But in the context of Google Cloud，Vertex AI is the right answer for general LLM usage on GCP,
72,下列哪個不是數據科學中常見的「探索性數據分析（EDA）」活動？,計算數據的平均值和標準差,繪製數據分佈的直方圖,訓練機器學習模型,查找數據集中的相關性,C,訓練機器學習模型屬於建模階段，而非探索。,
73,將原始數據轉換成適合分析的統一格式，是ETL中哪個階段的任務？,Extract,Transform,Load,Validate,B,Transform階段負責數據的清理和格式統一。,
74,下列哪個指標用於評估機器翻譯中，翻譯結果與參考譯文的相似度？,FID,MSE,BLEU,Perplexity,C,BLEU專為機器翻譯質量評估設計。,
75,在機器學習中，L2正則化的懲罰項是模型權重的什麼？,絕對值之和,平方和,倒數和,立方和,B,L2正則化懲罰權重的平方和。,
76,在設計一個對話機器人時，如果你希望它能夠生成自然流暢的回答，你會傾向於使用哪種類型的AI模型？,辨別式AI模型,生成式AI模型,迴歸模型,聚類模型,B,生成式AI模型擅長生成新的、連貫的內容。,
77,當數據集包含大量冗餘或不相關的特徵時，哪種正則化方法可能更具優勢？,L2 正則化,L1 正則化,不使用正則化,僅使用數據增強,B,L1正則化可以將冗餘特徵的權重歸零。,
78,一個有效的ETL流程對於數據倉庫的成功至關重要，因為它確保了數據的什麼？,豐富性,高度加密性,乾淨、一致和可靠性,快速備份能力,C,ETL的目標是數據質量和可用性。,
79,在歐盟AI法案中，對通用AI模型（GPAI，如GPT-4）引入了什麼額外要求？,必須開源所有程式碼,更嚴格的評估和風險管理要求,只能由歐盟公民開發,禁止用於商業用途,B,強大的GPAI模型面臨額外的透明度和風險管理義務。,
80,Position Encoding是將序列信息加到模型輸入的哪個部分？,模型的輸出層,詞元嵌入向量,損失函數,優化器,B,位置編碼向量通常加到詞元嵌入向量上。,
81,在強化學習中，「策略」是什麼？,衡量模型性能的指標,智能體在給定狀態下選擇動作的規則或函數,環境中可用的獎勵總和,數據預處理方法,B,策略定義了智能體的行為。,
82,邏輯迴歸模型使用Sigmoid函數的目的是什麼？,增加模型的線性度,將線性分數轉換為介於0到1之間的機率值,減少模型參數數量,處理非線性數據,B,Sigmoid函數將任意實數映射到(01)區間。,
83,下列哪個選項是數據科學中處理「維度詛咒」的常見方法？,增加數據維度,增加數據點數量,特徵選擇或降維,僅使用簡單的線性模型,C,特徵選擇和降維是應對維度詛咒的有效策略。,
84,如果一個機器學習模型在訓練集和測試集上的表現都很差，這表明模型可能存在什麼問題？,過擬合,欠擬合,良好的泛化能力,數據量過大,B,訓練和測試表現都差通常是欠擬合的跡象。,
85,用於評估圖像生成模型中，生成圖像與真實圖像分佈相似度的指標是？,ROUGE,BLEU,FID,Perplexity,C,FID是圖像生成質量評估的標準指標。,
86,歐盟AI法案中「不可接受的風險」AI系統的特點是？,可以通過嚴格監管後合法使用,對人類基本權利構成明確威脅，因此被禁止,僅需透明度聲明即可使用,鼓勵自願行為準則,B,不可接受風險的AI系統會被全面禁止。,
87,在Google Cloud中，如果你想使用AutoML功能來訓練模型，你會使用哪個服務？,TensorFlow,Keras,Vertex AI,PyTorch,C,Vertex AI整合了AutoML能力。,
88,下列哪項是L2正則化的一個主要優點？,自動進行特徵選擇,處理特徵間的高度共線性,產生稀疏模型,適用於所有數據類型,B,L2正則化通過穩定權重來處理共線性。,
89,MSE損失函數對哪種誤差更敏感？,小誤差,大誤差（異常值）,負誤差,正誤差,B,平方運算會放大較大的誤差。,
90,Position Encoding在Transformer模型中的哪個階段被加入？,在模型輸出層計算損失時,在輸入詞元嵌入之後，作為注意力機制的輸入之前,在數據預處理之前,在模型部署之後,B,位置編碼直接加到詞元嵌入上作為模型輸入。,
91,以下哪項不屬於大數據「Variety」的典型數據類型？,關聯式資料庫中的表格數據,音訊檔案,圖片數據,單一格式、單一來源的文本日誌,D,單一格式的數據缺乏多樣性。,
92,一個模型在訓練數據上表現完美，但在新的、未見過的數據上表現糟糕，這是什麼問題？,欠擬合,過擬合,泛化良好,維度詛咒,B,過擬合是典型的訓練集表現好，測試集表現差。,
93,L1和L2正則化都可以歸類為哪一類技術？,特徵選擇,數據清洗,防止過擬合,數據增強,C,正則化的核心目的是防止過擬合。,
94,在ETL流程中，處理數據質量（如修正錯誤、移除重複）是哪個階段的任務？,Extract,Transform,Load,Audit,B,數據質量處理屬於Transform階段的清洗任務。,
95,在強化學習中，與環境互動並基於獎勵調整自身行為的是誰？,觀察者,智能體 (Agent),訓練師,模型參數,B,智能體是學習和採取行動的主體。,
96,下列哪項是邏輯迴歸的優點？,擅長處理高度非線性的數據,輸出結果具有可解釋的機率,對異常值不敏感,自動進行特徵工程,B,邏輯迴歸的機率輸出使其具有良好解釋性。,
97,一個好的AI模型在訓練數據和測試數據上的表現應該如何？,訓練數據表現非常好，測試數據表現非常差,訓練數據表現差，測試數據表現差,訓練數據和測試數據上都表現良好且接近,測試數據表現好於訓練數據,C,理想模型應在兩者上都表現良好且平衡。,
98,在歐盟AI法案中，哪些AI系統被完全禁止？,高風險AI系統,不可接受的風險AI系統,有限風險AI系統,最低風險AI系統,B,不可接受風險類別的AI系統是完全禁止的。,
99,如果某個數據點在 $Q1 - 1.5 \times IQR$ 之下，它通常會被判定為什麼？,正常值,異常值 (Outlier),中位數,極大值,B,這個公式是判斷異常值的常用標準。,
100,V.A.E. 中的「變分 (Variational)」部分是指其編碼器輸出什麼？,單一的潛在向量,潛在空間中的一個機率分佈,一組離散的類別標籤,數據的原始特徵,B,變分自編碼器輸出的潛在空間是概率分佈。,
101,L2正則化的幾何解釋中，懲罰項的等高線是什麼形狀？,菱形,正方形,圓形,不規則形狀,C,L2懲罰項的等高線是圓形。,
102,L1正則化的幾何解釋中，懲罰項的等高線是什麼形狀？,圓形,橢圓形,菱形或正方形,拋物線形,C,L1懲罰項的等高線是菱形或正方形。,
103,在ETL流程中，如果數據來源是來自不同國家，且貨幣單位不同，那麼在哪個階段會進行貨幣單位的統一轉換？,Extract,Transform,Load,Monitor,B,數據統一化處理屬於Transform階段。,
104,什麼是AI模型評估中「忠實度 (Fidelity)」的衡量指標之一？,BLEU分數,FID分數,Perplexity,ROUGE分數,B,FID衡量生成圖像的真實性或忠實度。,
105,在歐盟AI法案中，用於輔助醫療診斷的AI系統通常被歸類為何種風險？,不可接受的風險,高風險,有限風險,最低風險,B,醫療設備中的AI屬於高風險類別。,
106,Position Encoding的目的是解決Transformer模型因為什麼原因而失去序列順序信息的問題？,計算效率低下,並行處理所有輸入詞元,僅能處理短序列,依賴梯度下降,B,並行處理導致模型無法感知位置。,
107,當訓練一個神經網路時，如果觀察到驗證集上的性能開始下降，而訓練集性能仍在提升，最適合採取的策略是？,繼續訓練更多世代,增加模型複雜度,使用早停法 (Early Stopping),減少訓練數據量,C,早停法用於防止過擬合。,
108,下列哪種模型屬於「集成學習」的範疇？,線性迴歸,支持向量機 (SVM),梯度提升樹 (Gradient Boosting Trees),K-近鄰 (KNN),C,梯度提升樹是另一種常見的集成學習方法。,
109,在大數據的5V特性中，哪一個V強調的是從數據中提取有意義的洞察和商業價值？,Volume,Velocity,Variety,Value,D,Value是數據分析的最終目標。,
110,在迴歸問題中，MSE對什麼樣的預測誤差給予更大的懲罰？,接近於零的小誤差,絕對值較大的誤差,負向誤差,正向誤差,B,平方運算使得大誤差的懲罰效果更顯著。,
111,「數據稀疏性」是高維度數據的一個常見問題，這意味著什麼？,數據點之間距離很近,數據點之間彼此非常遙遠，填充整個空間,數據量不足以訓練模型,數據中的特徵數量太少,B,在高維空間中，即使數據點很多，它們相對於整個可能空間仍然稀疏。,
112,在歐盟AI法案中，通常不需要額外法律義務，但鼓勵遵守自願行為準則的AI系統屬於哪種風險？,高風險,不可接受的風險,有限風險,最低風險,D,最低風險AI系統受到的監管最少。,
113,以下哪個不是鑑別式AI模型的典型應用？,圖像分類 (貓 vs 狗),垃圾郵件檢測,根據文本描述生成全新圖像,股票價格預測 (迴歸),C,生成全新圖像屬於生成式模型的任務。,
114,VAE的訓練目標函數中的「KL散度損失」目的是什麼？,確保生成圖像的清晰度,鼓勵編碼器輸出的潛在分佈接近標準正態分佈，使其平滑連續,減少模型計算量,避免數據過擬合,B,KL散度損失約束潛在空間的結構，利於採樣。,
115,哪種正則化方法在處理特徵之間的高度共線性時，傾向於將相關特徵的權重等比例縮小而不是歸零？,L1 正則化,L2 正則化,Elastic Net,Dropout,B,L2正則化對共線性更穩定，且不將權重歸零。,
116,在強化學習中，用於評估智能體行為好壞的信號是什麼？,損失函數,獎勵 (Reward),梯度,環境狀態,B,獎勵是智能體學習的指導信號。,
117,將原始文本轉換為TF-IDF向量後，詞彙表的大小可能達到數萬，這屬於大數據的哪個特性？,Volume,Velocity,Variety,Veracity,A,這裡主要體現了數據特徵數量（維度）的龐大，間接關聯Volume。,
118,一個設計精良的ETL流程最終目的是為誰提供乾淨、一致、可靠的數據？,程式設計師,數據分析師和業務決策者,數據庫管理員,網站訪客,B,ETL服務於數據分析和商業智能。,
119,如果希望一個AI模型能夠像人類一樣進行開放式對話，生成新的、連貫的回應，你最可能使用哪種類型的模型？,邏輯迴歸,支持向量機,大型語言模型 (LLM),決策樹,C,LLM是典型的生成式對話模型。,
120,在歐盟AI法案中，哪些AI系統的部署者在投入使用前可能需要進行「基本權利影響評估」？,最低風險AI系統,有限風險AI系統,高風險AI系統,禁止類AI系統,C,高風險AI系統對基本權利有潛在影響，需進行評估。,
121,在數據科學專案中，執行探索性數據分析（EDA）的主要目標是？,訓練機器學習模型,了解數據的特性、分佈和潛在模式,將數據載入到數據倉庫,部署模型到生產環境,B,EDA旨在初步理解數據。,
122,在編碼器-解碼器架構中，集束搜索（Beam Search）相比貪婪搜索的優勢是什麼？,更快的計算速度,更簡單的實現方式,更能找到全局較優的序列,不會產生任何錯誤,C,集束搜索通過考慮多個候選序列來提高生成質量。,
123,VAEs中的編碼器輸出的兩個向量分別代表潛在分佈的什麼？,最小值和最大值,均值和方差（或對數方差）,Q1和Q3,權重和偏置,B,均值和方差定義了潛在空間的概率分佈。,
124,在Google Cloud生態系統中，TensorFlow扮演的角色是什麼？,一個雲端服務平台,一個機器學習框架或程式庫,一個數據倉庫服務,一個數據視覺化工具,B,TensorFlow是底層的ML框架。,
125,你使用L1正則化訓練了一個模型，發現許多特徵的權重變成了零。這說明L1正則化實現了什麼功能？,數據增強,特徵選擇,模型欠擬合,數據標準化,B,L1的稀疏性導致特徵選擇。,
126,數據的「維度詛咒」在高維空間中會導致數據點之間什麼情況？,變得非常密集,彼此距離趨於相同，難以區分,形成清晰的聚類,呈現完美的線性關係,B,距離難以區分是維度詛咒的核心問題。,
127,如果一個數據集中的特徵範圍差異巨大（例如，一個特徵的數值在0-10000之間，另一個在0-1之間），哪種數據預處理方法最能幫助消除這種量綱差異？,數據去重,特徵標準化,數據增強,缺失值填補,B,標準化或縮放都能消除量綱。,
128,以下哪個場景最適合應用強化學習？,根據歷史數據預測房價,識別圖片中的貓和狗,訓練一個下棋AI，讓它學習如何贏得比賽,對客戶進行分群,C,下棋AI學習贏得比賽是典型的強化學習任務。,
129,歐盟AI法案強調確保AI系統具備「人類監督」能力，這通常是針對哪一類風險的AI系統？,最低風險,有限風險,高風險,不可接受的風險,C,高風險AI系統需要嚴格的人類監督。,
130,將AI模型部署到生產環境中，並讓其處理新的、實時數據以生成預測的過程，在數據科學流程中通常被稱為？,模型訓練,數據探索,模型推斷 (Inference),數據清洗,C,推斷是模型投入實際應用的步驟。,
131,在生成式對抗網路（GAN）中，FID分數的降低意味著什麼？,生成器（Generator）的性能變差,生成的圖像質量提高且更真實多樣,判別器（Discriminator）無法區分真假圖像,模型訓練發生模式崩潰,B,FID降低是生成圖像質量提高的指標。,
132,以下哪種是屬於大數據「Variety」特性下的非結構化數據類型？,SQL數據庫表格,JSON文件,社交媒體貼文或影片,CSV文件,C,社交媒體內容是典型的非結構化數據。,
133,在一個需要精確度而非絕對準確度的分類任務中，可能需要調整邏輯迴歸的什麼來優化模型？,輸入特徵的數量,Sigmoid函數的斜率,分類閾值,訓練數據的大小,C,調整閾值可以平衡精確度和召回率。,
134,Position Encoding通常會加到詞元嵌入向量上，這表示它在模型輸入前就完成了。這種加法是為了什麼？,改變詞元嵌入的維度,為每個詞元嵌入添加其位置信息，而不改變其語義本身,將詞元嵌入歸一化,減少模型訓練時間,B,位置編碼旨在為語義嵌入添加空間上下文。,
135,在大數據的「Veracity」特性中，我們主要關注的是數據的什麼？,數據的多樣性,數據的產生速度,數據的準確性和可信度,數據的存儲容量,C,Veracity關乎數據的質量和可靠性。,
136,如果你的數據集存在一些極端的異常值，並且你希望一個迴歸模型的損失函數對這些異常值不那麼敏感，你會考慮使用哪種損失函數？,均方誤差 (MSE),平均絕對誤差 (MAE),交叉熵損失,Hinge Loss,B,MAE對異常值比MSE更魯棒，因為它不進行平方。,
137,哪種AI模型是專為從文本描述生成圖像而設計的？,GPT-4,DALL-E,Whisper,Embeddings,B,DALL-E是OpenAI的文本到圖像生成模型。,
138,歐盟AI法案鼓勵對最低風險AI系統採取什麼措施？,強制性監管,完全禁止使用,自願遵守行為準則,嚴格的第三方驗證,C,最低風險AI鼓勵行業自律。,
139,處理高維度數據時，如果希望找到一個低維度的表示，並且這個表示能夠捕捉原始數據的最大方差，最適合使用哪種降維技術？,t-SNE,UMAP,主成分分析 (PCA),L1正則化,C,PCA旨在找到最大方差的方向進行投影。,
140,ETL流程中「Load」階段的「增量載入」方式有何優勢？,每次都重新載入所有數據,只載入自上次載入後新增或變化的數據，提高效率,需要更多的存儲空間,無法確保數據一致性,B,增量載入是處理大規模數據更新的有效方式。,
141,在一個推薦系統中，根據用戶的歷史瀏覽記錄和購買行為預測他是否會「點擊」某個廣告，這屬於哪種機器學習任務？,迴歸,分類,聚類,強化學習,B,「點擊」或「不點擊」是二元分類。,
142,VAE中的「潛在空間」理想狀態應該是怎麼樣的？,高度離散且無序,稀疏且難以解釋,連續且有意義，便於採樣生成,僅包含原始數據的精確副本,C,連續且有意義的潛在空間是VAE生成能力的基礎。,
143,當一個AI模型學到的決策邊界過於複雜和扭曲，試圖完美擬合訓練數據時，這最可能導致什麼問題？,欠擬合,過擬合,模型訓練速度慢,數據量不足,B,複雜的決策邊界是過擬合的典型表現。,
144,下列哪個不是防止AI模型過擬合的常用策略？,增加訓練數據量,使用Dropout,簡化模型複雜度,增加模型參數數量,D,增加模型參數數量通常會增加過擬合風險。,
145,如果你的模型在訓練初期，訓練集和驗證集上的損失都在持續下降，這表明什麼？,模型已經過擬合,模型正在有效學習，且泛化能力良好,模型欠擬合嚴重,數據中存在異常值,B,訓練和驗證損失同步下降是學習效果好的表現。,
146,Azure OpenAI服務的一個重要安全承諾是？,客戶數據將被用於訓練OpenAI的通用模型,客戶數據不會被用於訓練OpenAI的通用模型,服務僅支持公共網絡訪問,不提供任何內容過濾功能,B,保護客戶數據不被用於通用模型訓練是其關鍵承諾。,
147,在歐盟AI法案中，如果AI系統用於金融領域的「信用評分」，它通常會被歸類為何種風險？,最低風險,有限風險,高風險,不可接受的風險,C,信用評分系統對個人權利有重大影響，屬於高風險。,
148,以下哪種數據處理方式**不直接**用於減少高維度數據中的「噪音」或「冗餘」特徵？,L1正則化,主成分分析 (PCA),特徵選擇,數據增強 (Data Augmentation),D,數據增強是擴充數據量，而非直接降噪或去冗餘。,
149,MSE作為迴歸問題的損失函數，其缺點之一是它對什麼非常敏感？,模型參數的數量,訓練數據的數量,異常值（Outliers）,模型的解釋性,C,平方誤差的特性使其對異常值反應劇烈。,
150,下列哪種AI模型在歐盟AI法案中屬於「有限風險」，需要被明確標示是AI生成或修改的內容？,銀行交易詐欺檢測系統,用於工業生產線的機器視覺系統,深度偽造（Deepfakes）,智慧家電控制系統,C,Deepfakes需要明確披露其人工生成性質。,
151,在強化學習中，「PPO」是一種策略優化演算法，其全稱是？,Policy Prediction Optimization,Proximal Policy Optimization,Prioritized Policy Output,Parallel Policy Operations,B,Proximal Policy Optimization的縮寫。,
152,邏輯迴歸通常用於什麼類型的數據集，其決策邊界效果較好？,線性可分或近似線性的數據集,高度非線性的數據集,僅限於時間序列數據,僅限於圖像數據,A,邏輯迴歸本質上是線性模型。,
153,在數據預處理中，「數據增強 (Data Augmentation)」的主要目的是什麼？,減少數據的維度,增加數據的噪音,在不實際獲取新數據的情況下擴大訓練數據集的多樣性,將數據標準化,C,數據增強是透過轉換擴大訓練數據集。,
154,如果一個AI模型無法外推到比訓練時更長的序列，這最可能是哪種位置編碼的缺點？,正弦位置編碼,可學習的位置編碼,相對位置編碼,詞元嵌入,B,可學習位置編碼對未見長度序列的泛化能力差。,
155,大數據「Velocity」的特性，要求我們在處理數據時需要具備什麼能力？,更大的存儲空間,處理多種數據格式,實時或近實時的處理能力,識別數據真實性,C,高速數據流需要快速響應和處理。,
156,在一個預測是否會下雨的分類模型中，如果模型給出下雨的機率是0.7，且設定閾值為0.5，那麼模型會預測什麼？,不下雨,下雨,無法預測,需要改變閾值,B,0.7大於0.5，預測為「下雨」。,
157,ETL流程中，哪個階段會涉及對敏感數據進行匿名化或加密處理？,Extract,Transform,Load,Report,B,數據去敏化是Transform階段的數據治理任務。,
158,L2正則化對模型權重的影響是？,將所有權重壓縮為零,將所有權重壓縮到接近零，但很少完全為零,增加部分權重,使得權重分佈更廣,B,L2正則化會縮小所有權重但不歸零。,
159,如果一個AI模型在訓練集和驗證集上的損失都停滯不前且較高，這最可能表明什麼問題？,過擬合,欠擬合,泛化良好,數據量不足,B,訓練和驗證損失都高且無改善通常是欠擬合。,
160,歐盟AI法案鼓勵在監管沙盒中進行AI創新，這主要是為了什麼？,避免所有AI風險,促進負責任的AI開發和測試,加速AI模型的商業化部署,限制AI技術的發展,B,沙盒提供了受控的測試環境。,
161,VAE的潛在空間之所以能實現平滑連續的轉換（例如，從一張人臉平滑過渡到另一張人臉），是得益於哪部分損失函數的約束？,重建損失,KL散度損失,均方誤差,交叉熵損失,B,KL散度損失強制潛在分佈接近標準正態分佈。,
162,當你在處理高維度文本數據時，哪種技術最有可能幫助你降低維度並提取關鍵語義信息？,圖片像素化,PCA或Word Embeddings,音頻頻譜分析,時間序列預測,B,PCA可以降維，Word Embeddings本身就是將文本映射到低維向量空間。,
163,你正在評估一個用來生成詩歌的AI模型，你會使用哪種指標來評估其生成文本的流暢度和語義連貫性？,FID,MSE,Perplexity,AUC,C,困惑度是評估語言模型生成文本質量的重要指標。,
164,在ETL流程中，如果需要將多個來源的客戶數據合併，並處理不同來源中相同的客戶信息不一致問題，這是哪個階段的任務？,Extract,Transform,Load,Report,B,數據整合和清洗是Transform階段的核心任務。,
165,下列哪項是「特徵縮放 (Normalization)」的目的，而非「特徵標準化」？,將數據轉換為均值為0、標準差為1的分布,將數據壓縮到固定的範圍內（如[01]）,增加數據的多樣性,處理缺失值,B,特徵縮放旨在將數據映射到固定區間。,
166,在一個數據集中，如果大部分數據集中在Q1和Q3之間，這表示什麼？,數據分佈極度分散,數據存在大量異常值,中間50%的數據集中程度高,數據呈現正態分佈,C,IQR反映了數據中位數區域的集中程度。,
167,為什麼L2正則化在處理特徵共線性問題時更受青睞？,它會將共線特徵的權重歸零,它會將相關特徵的權重均勻地縮小，從而穩定模型,它會自動生成新的不相關特徵,它僅懲罰共線特徵,B,L2通過均勻壓縮所有權重來緩解共線性。,
168,在強化學習中，除了最大化累計獎勵，一個優良策略通常也考慮什麼？,最小化行為的隨機性,尋找長期穩定的平衡點，而不僅僅是短期最大獎勵,盡可能地利用所有可用的動作空間,避免與環境進行過多互動,B,RL通常追求長期累計獎勵最大化。,
169,如果一個AI模型學到的決策邊界過於簡單，連訓練數據都無法很好地擬合，這是什麼問題？,過擬合,欠擬合,泛化良好,數據量過大,B,過於簡單導致無法捕捉數據模式。,
170,下列哪個不是數據增強（Data Augmentation）的常見方法？,圖像旋轉或翻轉,文本同義詞替換,增加新的訓練數據集來源,圖像裁剪和縮放,C,數據增強是基於現有數據做變化，而非引入全新來源。,
171,在多數現代大型語言模型（LLM）中，如GPT系列，通常會採用哪種類型的模型架構？,循環神經網絡 (RNN),卷積神經網絡 (CNN),Transformer,支持向量機 (SVM),C,Transformer是LLM的基礎架構。,
172,歐盟AI法案對「不可接受的風險」AI系統的懲罰措施通常是什麼？,輕微警告,高額罰款並強制下架禁用,僅要求透明度聲明,鼓勵自願改正,B,禁止類AI系統面臨最嚴厲的懲罰。,
173,在數據探索（Explore）階段，繪製直方圖的主要目的是什麼？,訓練模型,觀察數據的分佈形態和集中趨勢,進行特徵選擇,載入數據,B,直方圖是探索數據分佈的常用視覺化工具。,
174,哪種詞元選擇方法在編碼器-解碼器架構中，會同時追蹤多條機率最高的詞元序列？,貪婪搜索,集束搜索,隨機採樣,最大機率選擇,B,集束搜索會維護K個最佳候選路徑。,
175,VAE中的「重建損失」衡量的是什麼？,編碼器輸出的潛在分佈與標準分佈的距離,解碼器重建的數據與原始輸入數據之間的相似度,模型預測的準確性,潛在空間的維度,B,重建損失確保了信息的壓縮和還原能力。,
176,Position Encoding的設計使得模型可以更容易學習到詞元之間的什麼關係？,語義相似度,絕對位置關係和相對位置關係,詞彙頻率,詞性標註,B,位置編碼旨在捕捉詞元在序列中的位置信息。,
177,L1正則化會促使模型產生更什麼樣的特徵權重分佈？,密集（所有權重都非零）,稀疏（部分權重為零）,平均分佈,隨機分佈,B,L1正則化引入稀疏性。,
178,在應用Lasso回歸（L1正則化）時，如果你發現許多不重要的特徵權重被自動設為零，這體現了Lasso的什麼能力？,抗噪能力,特徵選擇能力,加速收斂能力,處理非線性關係能力,B,Lasso的內建特徵選擇特性。,
179,「高維度數據」的挑戰之一是計算複雜度高，這意味著什麼？,處理數據需要更少的計算資源,許多演算法的計算成本會隨著維度增加而呈指數級增長,數據無法進行視覺化,模型訓練速度加快,B,高維度數據處理通常需要更多計算資源和時間。,
180,以下哪種數據處理步驟通常在ETL流程的「Transform」階段發生？,數據庫連接,創建新的衍生特徵,將數據分發到不同伺服器,報告生成,B,創建衍生特徵是數據轉換的一部分。,
181,如果你需要一個能夠分析時間序列數據中的異常模式的Azure AI服務，你會選擇？,電腦視覺,異常檢測器 (Anomaly Detector),翻譯器,人臉服務,B,異常檢測器專為此類任務設計。,
182,當一個機器學習模型在訓練集和驗證集上都表現不佳，且損失值很高，這最可能是什麼問題？,過擬合,欠擬合,數據量過大,模型過於複雜,B,訓練和驗證表現都差是欠擬合的典型表現。,
183,在一個分類任務中，如果希望模型能夠直接輸出每個類別的機率，那麼哪種模型是合適的選擇？,支持向量機 (SVM),邏輯迴歸,K-近鄰 (KNN),決策樹 (在沒有額外調整的情況下),B,邏輯迴歸的Sigmoid輸出就是概率。,
184,大數據的5V特性中，「Value」最終目的是要從數據中提取什麼？,隨機模式,無法理解的噪音,有意義的洞察和商業價值,更多的原始數據,C,Value代表數據的應用價值。,
185,在歐盟AI法案中，對「有限風險」AI系統的主要要求是什麼？,完全禁止使用,進行第三方合規評估,提供透明度聲明，告知使用者AI交互,僅供科學研究使用,C,透明度是有限風險AI的關鍵義務。,
186,什麼是機器學習模型「過擬合」的表現？,模型無法從訓練數據中學習,模型在訓練數據上表現完美，但在新數據上性能下降,模型過於簡單，無法捕捉數據模式,模型訓練時間過長,B,這是過擬合的經典定義。,
187,以下哪種AI模型在歐盟AI法案中被視為「不可接受的風險」？,推薦系統,學校考試評分系統,用於社會信用評分的AI系統,客戶服務聊天機器人,C,社會信用評分系統是明確禁止的AI系統。,
188,Position Encoding在Transformer中的作用類似於RNNs中的什麼？,記憶單元 (如LSTM的門控單元),循環連接，使其能夠處理序列信息,激活函數,損失函數,B,位置編碼彌補了Transformer缺乏RNNs循環連接帶來的序列感知能力。,
189,VAE中的「潛在表示」是什麼？,模型的最終預測結果,原始數據的壓縮、低維、有意義的隱藏特徵向量,模型的損失值,訓練數據的標籤,B,潛在表示是數據壓縮後的抽象特徵。,
190,如果你需要一個能夠執行高精度語音轉文本任務的OpenAI模型，你會選擇？,GPT-4,DALL-E,Whisper,Embeddings,C,Whisper專為高品質語音轉文本設計。,
191,在ETL流程中，如果數據來自多個不同的操作系統和應用程式，並且數據格式不統一，這主要屬於大數據的哪個特性挑戰？,Volume,Velocity,Variety,Veracity,C,數據格式的多樣性是Variety的挑戰。,
192,什麼是判斷一個數據點是否為異常值的常用方法，特別是結合四分位距（IQR）的？,計算平均值,觀察箱形圖（Box Plot）的鬍鬚之外的點,計算標準差,僅依靠最大值和最小值,B,箱形圖直接利用IQR來視覺化和識別異常值。,
193,Lasso回歸（L1正則化）的一個優點是它能使模型變得什麼？,更複雜,更慢,更稀疏（更簡潔）,對異常值更敏感,C,稀疏性是Lasso的特點，減少了模型複雜度。,
194,在機器學習中，衡量一個AI模型在未見過數據上表現好壞的能力稱為？,準確性,複雜度,泛化能力,特徵工程,C,泛化能力是模型實際應用能力的關鍵。,
195,如果一個AI系統的目標是預測客戶下個月的消費金額（一個具體的數字），這屬於哪種類型的機器學習任務？,分類,迴歸,聚類,強化學習,B,預測連續數值是迴歸任務。,
196,歐盟AI法案的一個主要目的是什麼？,限制所有AI技術的發展,促進AI創新同時確保安全和基本人權,要求所有AI模型必須開源,優先考慮經濟發展而非AI倫理,B,平衡創新與風險是法案核心。,
197,大數據的「Velocity」特性對數據基礎設施提出了什麼要求？,能夠儲存極大數據量,能夠快速攝取、處理和分析數據流,能夠處理多種格式數據,能夠確保數據100%準確,B,高速數據流要求基礎設施具備高吞吐和低延遲處理能力。,
198,在ETL流程中，「增量載入」主要關注的是？,每次都載入全部歷史數據,只載入自上次執行以來新增或修改的數據,減少轉換階段的複雜度,增加數據的多樣性,B,增量載入是為了提高載入效率，只處理變化部分。,
199,哪種AI模型通常會學習數據本身的生成分佈，並可以生成新的數據樣本？,辨別式模型,生成式模型,迴歸模型,線性模型,B,生成式模型是為了生成新數據。,
200,Position Encoding中，正弦位置編碼的獨特優點之一是它能夠處理什麼？,圖像數據,任意長度的序列,非線性關係,僅限於短序列,B,其函數形式使其對序列長度具有泛化能力。,
